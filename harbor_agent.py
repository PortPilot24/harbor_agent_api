import chromadb
import json
import sqlite3
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import logging
import google.generativeai as genai
import os
import re
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    metadata: Dict
    distance: float

class GeminiClient:
    """ë¬´ë£Œ Gemini API í´ë¼ì´ì–¸íŠ¸"""
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash-lite')
        self.generation_config = genai.types.GenerationConfig(
            temperature=0.1, max_output_tokens=2048, top_p=0.9, top_k=40
        )

    def generate_response(self, messages: List[Dict], tools: List[Dict] = None) -> Dict:
        """ë‹¨ì¼ JSON ê°ì²´ ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” ìµœì¢… ê°„ì†Œí™” ë²„ì „"""
        try:
            formatted_prompt = self._format_messages_for_gemini(messages)
            if tools:
                tool_descriptions = self._format_tools_for_prompt(tools)
                formatted_prompt += f"\n\n# ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡:\n{tool_descriptions}\n\n"
                formatted_prompt += """
# ì§€ì‹œì‚¬í•­:
- ë§Œì•½ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤ë©´, ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì— ë§ì¶° ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
{
  "reasoning": "ì™œ ì´ ë„êµ¬ë“¤ì„ ì„ íƒí–ˆëŠ”ì§€ì— ëŒ€í•œ ê°„ë‹¨í•œ ìƒê°.",
  "tool_calls": [
    {
      "function_name": "í˜¸ì¶œí•  ë„êµ¬ëª…",
      "arguments": {"ë§¤ê°œë³€ìˆ˜": "ê°’"}
    }
  ]
}

- ë§Œì•½ ë„êµ¬ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ë‹¤ë©´, ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì— ë§ì¶° ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
{
  "reasoning": "ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•œ ìƒê°.",
  "content": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… ë‹µë³€ ë‚´ìš©."
}
"""
            token_count = self.model.count_tokens(formatted_prompt)
            print("--- [API ìš”ì²­ ì „ í™•ì¸] ---")
            print(f"â–¶ ì „ì†¡ë  í”„ë¡¬í”„íŠ¸ ë‚´ìš©: \n{formatted_prompt}")
            print(f"â–¶ ì´ í† í° ìˆ˜: {token_count.total_tokens} ê°œ")
            print("--------------------------")

            response = self.model.generate_content(
                formatted_prompt, generation_config=self.generation_config
            )
            response_text = response.text.strip()

            try:
                match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if not match:
                    return {"type": "text", "content": response_text}

                json_str = match.group(0)
                parsed_response = json.loads(json_str, strict=False)

                if "tool_calls" in parsed_response and parsed_response["tool_calls"]:
                    return {"type": "tool_call_list", "calls": parsed_response["tool_calls"]}
                elif "content" in parsed_response:
                    return {"type": "text", "content": parsed_response["content"]}
                else:
                    return {"type": "text", "content": response_text}
            except json.JSONDecodeError:
                return {"type": "text", "content": response_text}
        except Exception as e:
            logger.error(f"Gemini API ì˜¤ë¥˜: {e}")
            # 429 Rate Limit ì˜¤ë¥˜ ì²˜ë¦¬
            if "429" in str(e):
                return {"type": "error", "content": "API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. 1ë¶„ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}
            return {"type": "error", "content": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    def _format_messages_for_gemini(self, messages: List[Dict]) -> str:
        formatted = ""
        for msg in messages:
            role, content = msg.get("role", ""), msg.get("content", "")
            if role == "system": formatted += f"# ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­:\n{content}\n\n"
            elif role == "user": formatted += f"# ì‚¬ìš©ì ì§ˆë¬¸:\n{content}\n\n"
            elif role == "assistant": formatted += f"# ì´ì „ ë‹µë³€:\n{content}\n\n"
            elif role == "tool": formatted += f"# ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:\n{content}\n\n"
        return formatted

    def _format_tools_for_prompt(self, tools: List[Dict]) -> str:
        tool_descriptions = []
        for tool in tools:
            func = tool.get("function", {})
            name, description = func.get("name", ""), func.get("description", "")
            parameters = func.get("parameters", {}).get("properties", {})
            param_desc = [f"  - {p_name} ({p_info.get('type', '')}): {p_info.get('description', '')}" for p_name, p_info in parameters.items()]
            tool_descriptions.append(f"â€¢ {name}: {description}\n" + "\n".join(param_desc))
        return "\n\n".join(tool_descriptions)

class ChromaDBManager:
    """ChromaDB ê´€ë¦¬ í´ë˜ìŠ¤"""
    def __init__(self, db_path: str = "./chroma_db"):  # ğŸ”„ ê²½ë¡œ ìˆ˜ì •
        self.client = chromadb.PersistentClient(path=db_path)
        self.legal_collection = None
        self.manual_collection = None
        try:
            self.legal_collection = self.client.get_collection(name="legal_docs")
            self.manual_collection = self.client.get_collection(name="legal_manuals")
            logger.info("ChromaDB ì»¬ë ‰ì…˜ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")

    def search_legal(self, query: str, n_results: int = 3, where_filter: Optional[Dict] = None) -> List[SearchResult]:
        if not self.legal_collection: return []
        try:
            results = self.legal_collection.query(query_texts=[query], n_results=n_results, where=where_filter)
            return [SearchResult(content=d, metadata=m, distance=dist) for d, m, dist in zip(results['documents'][0], results['metadatas'][0], results['distances'][0])]
        except Exception as e:
            logger.error(f"ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def search_manual(self, query: str, n_results: int = 3, where_filter: Optional[Dict] = None) -> List[SearchResult]:
        if not self.manual_collection: return []
        try:
            results = self.manual_collection.query(query_texts=[query], n_results=n_results, where=where_filter)
            return [SearchResult(content=d, metadata=m, distance=dist) for d, m, dist in zip(results['documents'][0], results['metadatas'][0], results['distances'][0])]
        except Exception as e:
            logger.error(f"ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

class HarborAgentTools:
    """Harbor Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë“¤"""
    def __init__(self, db_manager: ChromaDBManager):
        self.db_manager = db_manager

    @staticmethod
    def get_tool_definitions() -> List[Dict]:
        return [
            {"type": "function", "function": {"name": "search_legal_documents", "description": "í•­ë§Œ ê´€ë ¨ ë²•ë¥ , ê·œì •, ì¡°ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.", "parameters": {"type": "object", "properties": {"query": {"type": "string", "description": "ê²€ìƒ‰í•  ë²•ë¥  ë‚´ìš©"}, "structure_filter": {"type": "string", "description": "ë¬¸ì„œ êµ¬ì¡° í•„í„°(article, chapter ë“±)"}, "n_results": {"type": "integer", "description": "ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜(1-3)"}}, "required": ["query"]}}},
            {"type": "function", "function": {"name": "search_manual_documents", "description": "í•­ë§Œ ì—…ë¬´ ì ˆì°¨, ì•ˆì „ ë§¤ë‰´ì–¼, ì‹¤ë¬´ ê°€ì´ë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.", "parameters": {"type": "object", "properties": {"query": {"type": "string", "description": "ê²€ìƒ‰í•  ì ˆì°¨ë‚˜ ë°©ë²•"}, "n_results": {"type": "integer", "description": "ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜(1-3)"}}, "required": ["query"]}}},
        ]

    def execute_tool(self, tool_name: str, arguments: Dict) -> Dict:
        try:
            if tool_name == "search_legal_documents": return self._search_legal_documents(**arguments)
            elif tool_name == "search_manual_documents": return self._search_manual_documents(**arguments)
            else: return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"}
        except Exception as e:
            logger.error(f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜ {tool_name}: {e}")
            return {"error": f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

    def _format_search_results(self, results: List[SearchResult]) -> List[Dict]:
        if not results: return []
        return [{"content": r.content, "source_file": r.metadata.get('source_file', 'ì•Œ ìˆ˜ ì—†ìŒ')} for r in results]

    def _search_legal_documents(self, query: str, structure_filter: str = "", n_results: int = 2) -> Dict:
        where_filter = {"structure_type": structure_filter} if structure_filter else None
        results = self.db_manager.search_legal(query, n_results, where_filter)
        if not results: return {"message": "ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "results": []}
        return {"message": f"{len(results)}ê°œì˜ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.", "results": self._format_search_results(results)}

    def _search_manual_documents(self, query: str, n_results: int = 2) -> Dict:
        results = self.db_manager.search_manual(query, n_results)
        if not results: return {"message": "ê´€ë ¨ ë§¤ë‰´ì–¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "results": []}
        return {"message": f"{len(results)}ê°œì˜ ë§¤ë‰´ì–¼ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.", "results": self._format_search_results(results)}

class HarborAgent:
    """í•­ë§Œ ê·œì •ì•ˆë‚´ ë° ìƒí™©ëŒ€ì‘ Agent"""
    def __init__(self, api_key: str, db_path: str = "./chroma_db"):  # ğŸ”„ ë§¤ê°œë³€ìˆ˜ëª… ë³€ê²½ ë° ê²½ë¡œ ìˆ˜ì •
        self.gemini = GeminiClient(api_key)  # ğŸ”„ ë§¤ê°œë³€ìˆ˜ëª… ë³€ê²½
        self.db_manager = ChromaDBManager(db_path)
        self.tools = HarborAgentTools(self.db_manager)
        self.conversation_history = []

    def _create_system_prompt(self) -> str:
        return """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ í•­ë§Œ ê´€ë ¨ ì „ë¬¸ AI Assistantì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³ , 'ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ ì°¾ì€ ë’¤, ê·¸ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    # ë‹µë³€ ê·œì¹™
    1. ìµœìš°ì„ ì ìœ¼ë¡œ 'ë„êµ¬'ë¥¼ í†µí•´ ì°¾ì€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    2. ë§Œì¼ ë„êµ¬ë¡œ ì°¾ì€ ì •ë³´ê°€ ì§ˆë¬¸ì— ë‹µí•˜ê¸°ì— ë¶€ì¡±í•˜ê±°ë‚˜ ê´€ë ¨ì´ ì—†ë‹¤ë©´, "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ë°íˆì„¸ìš”.
    3. ë§Œì¼ ë„êµ¬ë¡œ ì°¾ì€ ì •ë³´ê°€ ì§ˆë¬¸ì— ë‹µí•˜ê¸°ì— ë¶€ì¡±í•˜ê±°ë‚˜ ê´€ë ¨ì´ ì—†ë‹¤ë©´, ì°¸ê³ ìš©ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•˜ì—¬ ì¸í„°ë„·ì—ì„œ ê²€ìƒ‰í•´ë³¸ í›„ ë‹µë³€ì„ ì¶”ê°€ë¡œ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    í•­ìƒ ì •í•´ì§„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."""
    
    def process_query(self, query: str) -> Dict:
        """
        ë‹¤ì¤‘ Tool Callì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©°, ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ê°•ì œë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë²„ì „
        """
        try:
            self.conversation_history.append({"role": "user", "content": query})
            messages = [{"role": "system", "content": self._create_system_prompt()}] + self.conversation_history
            tools = HarborAgentTools.get_tool_definitions()
            
            # API ìš”ì²­ íšŸìˆ˜ë¥¼ 2íšŒë¡œ ì œí•œ (ìµœì´ˆ 1íšŒ + ì¶”ê°€ ì •ë³´ ìš”ì²­ 1íšŒ)
            max_iterations = 2 
            iteration = 0
            tool_results_log = []

            while iteration < max_iterations:
                iteration += 1
                logger.info(f"--- [Agent ë°˜ë³µ {iteration}/{max_iterations}] ---")
                response = self.gemini.generate_response(messages, tools)

                if response["type"] == "tool_call_list":
                    # ëª¨ë¸ì´ ë„êµ¬ ì‚¬ìš©ì„ ìš”ì²­í•œ ê²½ìš°
                    for tool_call in response["calls"]:
                        function_name, arguments = tool_call["function_name"], tool_call.get("arguments", {})
                        logger.info(f"ë„êµ¬ í˜¸ì¶œ: {function_name} with {arguments}")
                        
                        # ë„êµ¬ ì‹¤í–‰
                        tool_result = self.tools.execute_tool(function_name, arguments)
                        tool_results_log.append({"tool": function_name, "arguments": arguments, "result": tool_result})
                        
                        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
                        messages.append({"role": "tool", "content": f"ë„êµ¬ '{function_name}' ì‹¤í–‰ ê²°ê³¼: {json.dumps(tool_result, ensure_ascii=False)}"})
                    
                    # ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ ê³„ì† ì§„í–‰
                    continue

                elif response["type"] == "text":
                    # ëª¨ë¸ì´ ë„êµ¬ ì—†ì´ ë°”ë¡œ ë‹µë³€ì„ ìƒì„±í•œ ê²½ìš°
                    self.conversation_history.append({"role": "assistant", "content": response["content"]})
                    return {"answer": response["content"], "tool_calls": tool_results_log, "iterations": iteration}

                else: # "error"
                    return {"answer": response.get("content", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."), "tool_calls": tool_results_log, "iterations": iteration}

            # --- âœ¨ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ ì‹œì‘ âœ¨ ---
            # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í•œ ê²½ìš°, ê°•ì œë¡œ ë‹µë³€ ìƒì„±
            logger.info(f"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations}íšŒ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            
            # ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ë¼ëŠ” ì§€ì‹œë¥¼ ì¶”ê°€
            final_instruction = "ì§€ê¸ˆê¹Œì§€ì˜ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëª¨ë‘ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ 'content' í•„ë“œì— ë‹´ì•„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë” ì´ìƒ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§Œì•½ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´, í˜„ì¬ê¹Œì§€ í™•ì¸ëœ ë‚´ìš©ê³¼ ì§ì ‘ íƒìƒ‰í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."
            messages.append({"role": "user", "content": final_instruction})
            
            # 'tools=None'ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë” ì´ìƒ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ëª»í•˜ë„ë¡ í•˜ê³  API í˜¸ì¶œ
            final_response = self.gemini.generate_response(messages, tools=None)
            
            if final_response["type"] == "text":
                final_answer = final_response["content"]
            else:
                # ë§ˆì§€ë§‰ í˜¸ì¶œì—ì„œë„ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ë‹µë³€ì´ ì—†ëŠ” ê²½ìš°
                final_answer = "ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."

            self.conversation_history.append({"role": "assistant", "content": final_answer})
            return {"answer": final_answer, "tool_calls": tool_results_log, "iterations": iteration}
            # --- âœ¨ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ ë âœ¨ ---

        except Exception as e:
            logger.error(f"process_query ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return {"answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "tool_calls": [], "iterations": 0}

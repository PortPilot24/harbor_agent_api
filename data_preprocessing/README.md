# 데이터 전처리 및 벡터 DB 생성 파이프라인

이 문서는 Harbor Agent API가 사용할 벡터 데이터베이스(ChromaDB)를 생성하는 데이터 전처리 파이프라인에 대해 설명합니다. 이 파이프라인은 원본 문서로부터 텍스트를 추출하고, 법률/매뉴얼의 구조를 분석하여 의미 있는 단위로 청킹(Chunking)한 뒤, 임베딩하여 ChromaDB에 저장하는 역할을 합니다.

## ✨ 주요 기능

  * **다중 파일 형식 지원**: `.docx`, `.pdf`, `.pptx` 형식의 원본 문서를 처리할 수 있습니다.
  * **법률 문서 특화 파싱**: '제1장', '제2조(목적)', '①항', '1.' 등 법률 문서의 고유한 계층 구조를 자동으로 인식하고 분석합니다.
  * **지능형 청킹(Chunking)**:
      * 문서의 구조적 경계(조, 항, 호)를 우선적으로 고려하여 청크를 생성합니다.
      * 긴 조항은 법률적 의미 단위(단서, 예외 조항 등)나 문장 단위로 자동 분할합니다.
      * 분할된 하위 청크(Sub-chunk)는 원본이 되는 상위 청크(Parent-chunk)와의 관계를 유지하여 검색 시 문맥을 함께 제공할 수 있습니다.
  * **메타데이터 강화**: 각 청크에 대해 원본 파일, 파일 해시, 구조 정보, 계층 경로, 시행일/공포일 등의 풍부한 메타데이터를 함께 저장하여 검색 시 필터링 및 결과 분석을 용이하게 합니다.
  * **증분 처리 (Incremental Processing)**: 파일의 해시(hash) 값을 `legal_metadata.db`에 기록하여, 변경되지 않은 파일은 다시 처리하지 않고 변경/추가된 파일만 처리하여 효율성을 높입니다.
  * **병렬 처리 지원**: 여러 파일을 동시에 처리하여 대량의 문서 처리 시간을 단축합니다.

## ⚙️ 실행 전 준비사항

1.  **필수 라이브러리 설치**: 노트북의 첫 번째 코드 셀을 실행하여 필요한 모든 Python 패키지를 설치합니다.
    ```bash
    !pip install python-docx chromadb sentence-transformers "transformers>=4.32.0" "torch>=2.0.0" "accelerate" pymupdf python-pptx
    ```
2.  **Google Colab 환경 권장**: 임베딩 모델 로드 및 병렬 처리는 상당한 메모리(RAM)와 CPU를 요구하므로, 로컬 환경보다는 Google Colab Pro 또는 고사양의 가상 머신에서 실행하는 것을 권장합니다.
3.  **Google Drive 연동 (Colab 사용 시)**: Colab에서 실행할 경우, Google Drive를 마운트해야 원본 데이터와 생성된 DB를 영구적으로 저장할 수 있습니다.
    ```python
    from google.colab import drive
    drive.mount('/content/drive')
    ```

## 🚀 사용 방법

1.  **원본 데이터 준비**:

      * 이 `README.md` 파일이 있는 위치에 `data` 라는 이름의 폴더를 생성합니다.
      * 처리하고자 하는 모든 원본 문서 파일(`.docx`, `.pdf`, `.pptx`)을 `data` 폴더 안에 넣습니다.

2.  **`Config` 클래스 설정 수정**:

      * `data_preprocessing_code.ipynb` 노트북을 엽니다.
      * `Config` 클래스가 정의된 셀을 찾아 아래 항목들을 자신의 환경에 맞게 수정합니다.
          * `DOCX_DIRECTORY`: 원본 문서가 저장된 경로입니다. **1번 단계에서 `data` 폴더를 만들었다면, 이 경로를 해당 폴더로 지정해야 합니다.** (예: `/content/drive/MyDrive/project/data_preprocessing/data`)
          * `DB_PATH`: ChromaDB 파일들이 저장될 경로입니다. (기본값: `/content/chroma_db`)
          * `COLLECTION_NAME`: ChromaDB 내에서 데이터를 그룹화하는 단위입니다. **`"legal_docs"`(법률) 또는 `"legal_manuals"`(매뉴얼) 중 처리할 문서 종류에 맞게 주석을 해제하거나 수정하세요.** API 서버의 도구(Tool)가 이 이름을 기준으로 검색하므로 매우 중요합니다.
          * `ENABLE_PARALLEL`: 파일이 많을 경우 `True`로 설정하여 병렬 처리를 활성화합니다.

3.  **파이프라인 실행**:

      * Jupyter Notebook의 모든 셀을 **처음부터 끝까지 순서대로 실행**합니다.
      * 실행이 시작되면 각 파일의 처리 상태, 청크 추출 수, DB 저장 과정 등이 로그로 출력됩니다.

4.  **결과물 확인**:

      * 실행이 성공적으로 완료되면 `Config` 클래스에 지정한 `DB_PATH` 경로에 `chroma_db` 폴더가 생성됩니다.
      * 같은 경로에 `legal_metadata.db` 파일도 생성되며, 이 파일은 어떤 파일이 처리되었는지 기록하는 역할을 합니다.
      * 이 결과물들을 API 서버가 읽을 수 있도록 경로를 올바르게 설정해야 합니다.

## ⚠️ 한계점 및 개선 방향

  * **스캔 기반 PDF/이미지 처리 불가**: 현재 파이프라인은 텍스트가 추출 가능한(Searchable) PDF만 처리할 수 있습니다. 이미지로 된 페이지나 스캔된 문서는 텍스트를 인식하지 못합니다.
      * **개선 방향**: Tesseract와 같은 OCR(광학 문자 인식) 라이브러리를 통합하여 이미지 기반 문서에서도 텍스트를 추출하는 기능을 추가할 수 있습니다.
  * **복잡한 테이블 구조**: 테이블을 Markdown 형식으로 변환하지만, 셀 병합(merge)이 매우 복잡하거나 비정형적인 테이블의 경우 구조가 깨지거나 내용이 누락될 수 있습니다.
      * **개선 방향**: 테이블의 구조를 더 정교하게 분석하거나, 테이블을 이미지로 캡처한 후 OCR로 처리하는 등 별도의 테이블 처리 로직을 강화할 수 있습니다.
  * **일관되지 않은 문서 양식**: 파서는 '제1조', '①' 와 같이 일관된 법률/행정 문서 양식을 가정합니다. 문서마다 양식이 크게 다를 경우, 구조 분석의 정확도가 떨어질 수 있습니다.
      * **개선 방향**: 더 많은 예외 패턴을 추가하고, 정규식 기반 파싱 외에 LLM을 활용하여 문서 구조를 동적으로 파악하는 방안을 고려할 수 있습니다.
  * **임베딩 모델 의존성**: 최종 검색 품질은 `Config`에 설정된 임베딩 모델의 성능에 크게 좌우됩니다. 현재 선택된 `jhgan/ko-sroberta-multitask` 모델은 범용적으로 성능이 좋지만, 항만 법률 분야에 100% 최적화된 모델은 아닐 수 있습니다.
      * **개선 방향**: 항만 분야의 Q\&A 데이터셋을 구축하고, 이를 기반으로 여러 임베딩 모델의 성능(예: MRR, Hit Rate)을 실증적으로 평가하여 최적의 모델을 선정하거나, 직접 모델을 미세조정(Fine-tuning)하는 작업을 수행할 수 있습니다.